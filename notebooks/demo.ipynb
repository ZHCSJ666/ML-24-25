{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import rootutils\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "ROOT = rootutils.setup_root(\".\", \".project-root\", pythonpath=True)\n",
    "\n",
    "from src.demo_inference import load_run\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_path = (\n",
    "    ROOT / \"logs/train/runs/2025-01-24_23-12-54/checkpoints/epoch_023-val_MRR_top5_0.6524.ckpt\"\n",
    ")\n",
    "our_model, datamodule = load_run(checkpoint_path)\n",
    "\n",
    "baseline_tokenizer = AutoTokenizer.from_pretrained(\"JetBrains-Research/cmg-codet5-without-history\")\n",
    "baseline_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"JetBrains-Research/cmg-codet5-without-history\"\n",
    ")\n",
    "baseline_model = baseline_model.to(device)\n",
    "\n",
    "csv_path = ROOT / \"notebooks/comparisons.csv\"\n",
    "samples = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def generate_baseline_message(diff: str) -> str:\n",
    "    \"\"\"Generate commit message using the baseline model.\"\"\"\n",
    "    inputs = baseline_tokenizer(diff, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = baseline_model.generate(**inputs)\n",
    "    return baseline_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def evaluate_messages(baseline_message: str, target_message: str, diff: str) -> dict:\n",
    "    \"\"\"Evaluate messages using OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"Given a code diff and two commit messages (one from a model and one target message), \n",
    "    evaluate the model message on a scale of 1-10 based on how well it captures the essence of the target message\n",
    "    while maintaining clarity and relevance to the changes.\n",
    "\n",
    "    Code diff:\n",
    "    {diff}\n",
    "\n",
    "    Model Message: {baseline_message}\n",
    "    Target Message: {target_message}\n",
    "\n",
    "    Provide your response in JSON format:\n",
    "    {{\n",
    "        \"score\": <score>,\n",
    "        \"explanation\": \"<brief explanation of the score>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "        response_format={\"type\": \"json\"},\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.demo_inference import generate_commit_message\n",
    "from src.evaluate_commits import CommitMessageEvaluator\n",
    "\n",
    "evaluator = CommitMessageEvaluator(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "sample = samples.iloc[0]\n",
    "print(\"Sample 1 Diff:\\n\", sample[\"input\"][:200] + \"...\\n\")\n",
    "\n",
    "our_message = generate_commit_message(our_model, sample[\"input\"])\n",
    "baseline_message = generate_baseline_message(sample[\"input\"])\n",
    "\n",
    "print(\"Our Model's Message:\", our_message)\n",
    "print(\"Baseline Message:\", baseline_message)\n",
    "print(\"Target Message:\", sample[\"target\"])\n",
    "\n",
    "evaluation = evaluator.evaluate_messages(\n",
    "    tiny_message=our_message,\n",
    "    baseline_message=baseline_message,\n",
    "    target_message=sample[\"target\"],\n",
    "    diff=sample[\"input\"],\n",
    ")\n",
    "print(\"\\nEvaluation:\", json.dumps(evaluation, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
