{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a643813c04681d7",
   "metadata": {},
   "source": [
    "# Data Collator Experiments\n",
    "\n",
    "In this notebook, we'll explore how to construct batches out of processed `Commit Chronicle` dataset during the training/validation setting for a encoder-decoder style architecture.\n",
    "\n",
    "**Make sure to run `Commit Chronicle Dataset.ipynb` before using this notebook.**\n",
    "\n",
    "The logic laid out in this notebook is implemented in `DataCollatorTrain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d582a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:42.359455Z",
     "start_time": "2024-11-09T07:11:39.362450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rootutils\n",
    "import torch.utils.data\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from src.data.types import SingleExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8271185ef40822a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:42.365553Z",
     "start_time": "2024-11-09T07:11:42.361964Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = rootutils.find_root(\".\", \".project-root\")\n",
    "OUTPUT_DIR = ROOT / \"data/playground\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66560668fa852eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:42.739422Z",
     "start_time": "2024-11-09T07:11:42.569554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['author', 'msg_input_ids', 'diff_input_ids', 'language', 'repo'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ = load_from_disk(OUTPUT_DIR / \"02-processed-validation\")\n",
    "dataset_.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21977b087089398c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:42.777409Z",
     "start_time": "2024-11-09T07:11:42.773621Z"
    }
   },
   "outputs": [],
   "source": [
    "class HumbleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index: int) -> SingleExample:\n",
    "        row = self.dataset[index]\n",
    "        return SingleExample(\n",
    "            diff_input_ids=row[\"diff_input_ids\"],\n",
    "            msg_input_ids=row[\"msg_input_ids\"],\n",
    "            history_input_ids=[],  # ignored in this notebook. don't worry about it. trust me :)\n",
    "            pos_in_file=-1,  # ignored in this notebook.\n",
    "        )\n",
    "\n",
    "\n",
    "data = HumbleDataset(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d18fd5dede64a7c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:44.009361Z",
     "start_time": "2024-11-09T07:11:42.826058Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data.components.tokenization import add_special_tokens\n",
    "from transformers import AutoTokenizer\n",
    "from copy import deepcopy\n",
    "\n",
    "msg_tokenizer_ = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "msg_tokenizer_ = add_special_tokens(msg_tokenizer_, None)\n",
    "diff_tokenizer_ = deepcopy(msg_tokenizer_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab645ac76704b58",
   "metadata": {},
   "source": [
    "# Encoder Input Processing\n",
    "\n",
    "Here we assume input to the encoder is the git diff, `diff_input_ids` attribute of `SingleExample`. It can also be history of all git diffs, but we don't use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5347e3cf34422c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:44.018397Z",
     "start_time": "2024-11-09T07:11:44.012358Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m\n\u001b[1;32m     48\u001b[0m     masks_tensors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m         _pad_tensor(\n\u001b[1;32m     50\u001b[0m             tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m masks_tensors\n\u001b[1;32m     56\u001b[0m     ]\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(inputs_tensors), torch\u001b[38;5;241m.\u001b[39mstack(masks_tensors)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pad_tensor\u001b[39m(\n\u001b[0;32m---> 61\u001b[0m     input_tensor: \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mTensor, pad_len: \u001b[38;5;28mint\u001b[39m, value: \u001b[38;5;28mint\u001b[39m, left: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     62\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     64\u001b[0m         input_tensor,\n\u001b[1;32m     65\u001b[0m         pad\u001b[38;5;241m=\u001b[39m[pad_len, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, pad_len],\n\u001b[1;32m     66\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m     68\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def process_encoder_inputs(\n",
    "    input_ids_batch: list[list[int]],\n",
    "    encoder_context_max_len: int,\n",
    "    bos_token_id: int,\n",
    "    eos_token_id: int,\n",
    "    pad_token_id: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    This helper method processes either diffs or messages as encoder input.\n",
    "\n",
    "    It truncates the inputs to the maximum allowed length.\n",
    "\n",
    "    It also adds all required special tokens: format is [BOS] input [EOS].\n",
    "\n",
    "    Finally, it is responsible for padding to maximum length in batch and conversion to torch.Tensor.\n",
    "\n",
    "    Args:\n",
    "        input_ids_batch: A list of tokenized examples from the current batch.\n",
    "        encoder_context_max_len: The maximum length of the encoder context.\n",
    "        bos_token_id: The value of the beginning of sequence (BOS) token.\n",
    "        eos_token_id: The value of the end of sequence (EOS) token.\n",
    "        pad_token_id: The value of the padding token (PAD) token.\n",
    "\n",
    "    Returns:\n",
    "        input_ids for encoder, attention_mask for encoder\n",
    "    \"\"\"\n",
    "\n",
    "    # add BOS and EOS tokens to each example whilst making sure max length of resulting token list is encoder_context_max_len\n",
    "    input_ids_batch = [\n",
    "        [bos_token_id] + example[: encoder_context_max_len - 2] + [eos_token_id]\n",
    "        for example in input_ids_batch\n",
    "    ]\n",
    "    inputs_tensors = [torch.tensor(ids, dtype=torch.int64) for ids in input_ids_batch]\n",
    "\n",
    "    # pad tensors to max length in batch\n",
    "    inputs_max_len = max(len(tensor) for tensor in input_ids_batch)\n",
    "    inputs_tensors = [\n",
    "        _pad_tensor(\n",
    "            tensor,\n",
    "            pad_len=inputs_max_len - tensor.numel(),\n",
    "            value=pad_token_id,\n",
    "            left=False,\n",
    "        )\n",
    "        for tensor in inputs_tensors\n",
    "    ]\n",
    "\n",
    "    masks_tensors = [torch.ones_like(ids) for ids in inputs_tensors]\n",
    "    masks_tensors = [\n",
    "        _pad_tensor(\n",
    "            tensor,\n",
    "            pad_len=inputs_max_len - tensor.numel(),\n",
    "            value=0,\n",
    "            left=False,\n",
    "        )\n",
    "        for tensor in masks_tensors\n",
    "    ]\n",
    "    return torch.stack(inputs_tensors), torch.stack(masks_tensors)\n",
    "\n",
    "\n",
    "def _pad_tensor(\n",
    "    input_tensor: torch.Tensor, pad_len: int, value: int, left: bool\n",
    ") -> torch.Tensor:\n",
    "    return torch.nn.functional.pad(\n",
    "        input_tensor,\n",
    "        pad=[pad_len, 0] if left else [0, pad_len],\n",
    "        mode=\"constant\",\n",
    "        value=value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7aa941fcb1555",
   "metadata": {},
   "source": [
    "Let's try it out with a batch size of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54c9d6da4cdf12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:44.037073Z",
     "start_time": "2024-11-09T07:11:44.031102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 512]), torch.Size([2, 512]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_ = [data[0], data[1]]\n",
    "git_diff_inputs_ = [example.diff_input_ids for example in examples_]\n",
    "encoder_input_ids_, encoder_attention_mask_ = process_encoder_inputs(\n",
    "    input_ids_batch=git_diff_inputs_,\n",
    "    encoder_context_max_len=512,  # this is a hyperparameter\n",
    "    bos_token_id=diff_tokenizer_.bos_token_id,\n",
    "    eos_token_id=diff_tokenizer_.eos_token_id,\n",
    "    pad_token_id=diff_tokenizer_.pad_token_id,\n",
    ")\n",
    "encoder_input_ids_.shape, encoder_attention_mask_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89460b619b8d24fc",
   "metadata": {},
   "source": [
    "That's it. The output data forms input to our encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51094f1f0c486b",
   "metadata": {},
   "source": [
    "# Decoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c47d6d0e78d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:44.063797Z",
     "start_time": "2024-11-09T07:11:44.053431Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "def _process_decoder_input(\n",
    "    examples: list[SingleExample],\n",
    "    msg_bos_token_id: int,\n",
    "    msg_eos_token_id: int,\n",
    "    msg_pad_token_id: int,\n",
    "    decoder_context_max_len,\n",
    "    shift_labels: bool,\n",
    "    decoder_start_token_id: Optional[int] = None,\n",
    "    # ignore these options\n",
    "    encoder_input_type: Literal[\"diff\", \"history\"] = \"diff\",\n",
    "    with_history: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares decoder input for train/validation:\n",
    "      * aggregates messages from history when configured accordingly\n",
    "      * concatenates history with current message\n",
    "      * constructs labels\n",
    "      * pads, converts to tensors\n",
    "\n",
    "    Args:\n",
    "        examples: A list of inputs for current batch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of three tensors: input ids, attention masks, labels.\n",
    "    \"\"\"\n",
    "    message_inputs: list[list[int]] = [example.msg_input_ids for example in examples]\n",
    "    history_inputs: list[list[list[int]]] = [\n",
    "        example.history_input_ids for example in examples\n",
    "    ]\n",
    "\n",
    "    all_msg_ids: list[torch.Tensor] = []\n",
    "    all_msg_masks: list[torch.Tensor] = []\n",
    "    all_msg_labels: list[torch.Tensor] = []\n",
    "\n",
    "    for message_ids, history_ids in zip(message_inputs, history_inputs):\n",
    "        message_ids = message_ids[: decoder_context_max_len - 2]\n",
    "\n",
    "        cur_history_ids = []\n",
    "        cur_history_labels = []\n",
    "\n",
    "        # if encoder_input_type != \"history\" and with_history:\n",
    "        #     cur_history_ids = _get_history(\n",
    "        #         cur_len=len(message_ids) + 2,\n",
    "        #         history_ids=history_ids,\n",
    "        #     )\n",
    "        #     cur_history_labels = [\n",
    "        #         [-100 for _ in message] for message in cur_history_ids\n",
    "        #     ]\n",
    "\n",
    "        cur_ids = (\n",
    "            [[msg_bos_token_id]]\n",
    "            + cur_history_ids\n",
    "            + [message_ids]\n",
    "            + [[msg_eos_token_id]]\n",
    "        )\n",
    "        cur_labels = (\n",
    "            [[msg_bos_token_id]]\n",
    "            + cur_history_labels\n",
    "            + [message_ids]\n",
    "            + [[msg_eos_token_id]]\n",
    "        )\n",
    "\n",
    "        if shift_labels:\n",
    "            cur_ids, cur_labels = _shift_for_encoder_decoder(\n",
    "                cur_ids,\n",
    "                cur_labels,\n",
    "                msg_bos_token_id=msg_bos_token_id,\n",
    "                decoder_start_token_id=decoder_start_token_id,\n",
    "            )\n",
    "\n",
    "        cur_ids_tensor = torch.tensor(\n",
    "            [ex for sublist in cur_ids for ex in sublist], dtype=torch.int64\n",
    "        )\n",
    "        cur_labels_tensor = torch.tensor(\n",
    "            [ex for sublist in cur_labels for ex in sublist], dtype=torch.int64\n",
    "        )\n",
    "        cur_mask_tensor = torch.ones_like(cur_ids_tensor)\n",
    "\n",
    "        all_msg_ids.append(cur_ids_tensor)\n",
    "        all_msg_masks.append(cur_mask_tensor)\n",
    "        all_msg_labels.append(cur_labels_tensor)\n",
    "\n",
    "    msg_max_len = max(len(tensor) for tensor in all_msg_ids)\n",
    "    all_msg_ids = [\n",
    "        _pad_tensor(\n",
    "            tensor,\n",
    "            pad_len=msg_max_len - tensor.numel(),\n",
    "            value=msg_pad_token_id,\n",
    "            left=False,\n",
    "        )\n",
    "        for tensor in all_msg_ids\n",
    "    ]\n",
    "    all_msg_masks = [\n",
    "        _pad_tensor(\n",
    "            tensor,\n",
    "            pad_len=msg_max_len - tensor.numel(),\n",
    "            value=0,\n",
    "            left=False,\n",
    "        )\n",
    "        for tensor in all_msg_masks\n",
    "    ]\n",
    "    all_msg_labels = [\n",
    "        _pad_tensor(\n",
    "            tensor,\n",
    "            pad_len=msg_max_len - tensor.numel(),\n",
    "            value=-100,\n",
    "            left=False,\n",
    "        )\n",
    "        for tensor in all_msg_labels\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        torch.stack(all_msg_ids),\n",
    "        torch.stack(all_msg_masks),\n",
    "        torch.stack(all_msg_labels),\n",
    "    )\n",
    "\n",
    "\n",
    "def _shift_for_encoder_decoder(\n",
    "    ids: list[list[int]],\n",
    "    labels: list[list[int]],\n",
    "    msg_bos_token_id: int,\n",
    "    decoder_start_token_id: Optional[int] = None,\n",
    ") -> tuple[list[list[int]], list[list[int]]]:\n",
    "    \"\"\"This method mimics transformers logic of ids and labels for EncoderDecoderModel\n",
    "    (or T5ForConditionalGeneration).\n",
    "\n",
    "    Starting from transformers v4.12, loss is now calculated in EncoderDecoderModel, not in decoder class.\n",
    "    Also, decoder input ids are created automatically based on labels: labels are shifted and -100 is replaced\n",
    "    with pad token. In our case, history ids are masked -100 in labels, but they are still\n",
    "    meaningful ids. Therefore, we can't use the default approach.\n",
    "    \"\"\"\n",
    "    if decoder_start_token_id is None:\n",
    "        ids = [[msg_bos_token_id]] + ids[:-1]\n",
    "    else:\n",
    "        ids = [[decoder_start_token_id]] + ids[:-1]\n",
    "    return ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d112c8309ce4be49",
   "metadata": {},
   "source": [
    "Trying it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd125d3780d419c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:44.082015Z",
     "start_time": "2024-11-09T07:11:44.077804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 26]), torch.Size([2, 26]), torch.Size([2, 26]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids_, decoder_attention_mask_, labels_ = _process_decoder_input(\n",
    "    examples=examples_,\n",
    "    msg_bos_token_id=msg_tokenizer_.bos_token_id,\n",
    "    msg_eos_token_id=msg_tokenizer_.eos_token_id,\n",
    "    msg_pad_token_id=msg_tokenizer_.pad_token_id,\n",
    "    decoder_context_max_len=512,  # this is a hyperparam for the model\n",
    "    shift_labels=True,\n",
    ")\n",
    "decoder_input_ids_.shape, decoder_attention_mask_.shape, labels_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caff40753de02be",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acff07ec03fcb9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:46.378208Z",
     "start_time": "2024-11-09T07:11:44.095188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa170c76f9684dedad17be9953b325bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3f3e9d745a44c499cac3cf53e53d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/52/3e/523e1421c7095eb4d05179067b2114bc202bf646ef4656a23378055f26b58ba0/495fa51e204676f1a857a9fc13c4c89f3f5ba9f480b898cebca02add25e6d749?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731447891&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQ0Nzg5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy81Mi8zZS81MjNlMTQyMWM3MDk1ZWI0ZDA1MTc5MDY3YjIxMTRiYzIwMmJmNjQ2ZWY0NjU2YTIzMzc4MDU1ZjI2YjU4YmEwLzQ5NWZhNTFlMjA0Njc2ZjFhODU3YTlmYzEzYzRjODlmM2Y1YmE5ZjQ4MGI4OThjZWJjYTAyYWRkMjVlNmQ3NDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hAz-i2JZSYX6iDXbSeUbXeXTHq8KcTR96kI9Y4XqLmqfx8ra7rWwDTUExWmYLQR-oxvYR3MHM5jCabPdCxd5KyXFt1QdRzSqOkWpgDt%7EyFSKdExKKO7OtsxGnZlSbv91k1yMmUP2EMjpV3aMA1gVJbR1ukaG7odYNZJ1lH4NHUq%7ELglC6VcAQO6P1u9QM6lWG2J3DTrdE4ungtNcr3fhgwLbP%7EtOiSjSSS2WVrfehStUno93gDEctFuB4gTzy1IH3dfUPkZRK3TNuuD%7E8c%7E9U6Ae7brYfpu%7EFmm1lvJZhHWjZepswyfc45gS9GD9tjAR2INFQqqUwUIi43KdC8pxaQ__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7c82a1b5b14094bc075b5f700d8890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   3%|3         | 10.5M/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/52/3e/523e1421c7095eb4d05179067b2114bc202bf646ef4656a23378055f26b58ba0/495fa51e204676f1a857a9fc13c4c89f3f5ba9f480b898cebca02add25e6d749?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731447891&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQ0Nzg5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy81Mi8zZS81MjNlMTQyMWM3MDk1ZWI0ZDA1MTc5MDY3YjIxMTRiYzIwMmJmNjQ2ZWY0NjU2YTIzMzc4MDU1ZjI2YjU4YmEwLzQ5NWZhNTFlMjA0Njc2ZjFhODU3YTlmYzEzYzRjODlmM2Y1YmE5ZjQ4MGI4OThjZWJjYTAyYWRkMjVlNmQ3NDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hAz-i2JZSYX6iDXbSeUbXeXTHq8KcTR96kI9Y4XqLmqfx8ra7rWwDTUExWmYLQR-oxvYR3MHM5jCabPdCxd5KyXFt1QdRzSqOkWpgDt%7EyFSKdExKKO7OtsxGnZlSbv91k1yMmUP2EMjpV3aMA1gVJbR1ukaG7odYNZJ1lH4NHUq%7ELglC6VcAQO6P1u9QM6lWG2J3DTrdE4ungtNcr3fhgwLbP%7EtOiSjSSS2WVrfehStUno93gDEctFuB4gTzy1IH3dfUPkZRK3TNuuD%7E8c%7E9U6Ae7brYfpu%7EFmm1lvJZhHWjZepswyfc45gS9GD9tjAR2INFQqqUwUIi43KdC8pxaQ__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92e588642144b6da3863ea54aa0838c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   7%|6         | 21.0M/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/52/3e/523e1421c7095eb4d05179067b2114bc202bf646ef4656a23378055f26b58ba0/495fa51e204676f1a857a9fc13c4c89f3f5ba9f480b898cebca02add25e6d749?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1731447891&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTQ0Nzg5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy81Mi8zZS81MjNlMTQyMWM3MDk1ZWI0ZDA1MTc5MDY3YjIxMTRiYzIwMmJmNjQ2ZWY0NjU2YTIzMzc4MDU1ZjI2YjU4YmEwLzQ5NWZhNTFlMjA0Njc2ZjFhODU3YTlmYzEzYzRjODlmM2Y1YmE5ZjQ4MGI4OThjZWJjYTAyYWRkMjVlNmQ3NDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hAz-i2JZSYX6iDXbSeUbXeXTHq8KcTR96kI9Y4XqLmqfx8ra7rWwDTUExWmYLQR-oxvYR3MHM5jCabPdCxd5KyXFt1QdRzSqOkWpgDt%7EyFSKdExKKO7OtsxGnZlSbv91k1yMmUP2EMjpV3aMA1gVJbR1ukaG7odYNZJ1lH4NHUq%7ELglC6VcAQO6P1u9QM6lWG2J3DTrdE4ungtNcr3fhgwLbP%7EtOiSjSSS2WVrfehStUno93gDEctFuB4gTzy1IH3dfUPkZRK3TNuuD%7E8c%7E9U6Ae7brYfpu%7EFmm1lvJZhHWjZepswyfc45gS9GD9tjAR2INFQqqUwUIi43KdC8pxaQ__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb820e71ec14461f8f5e355f6070dbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   7%|6         | 21.0M/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2493e323fa48d3bd7baa082b4364dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "719ffd6afe276cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:46.745202Z",
     "start_time": "2024-11-09T07:11:46.397566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'copy',\n",
       " 'cross_attentions',\n",
       " 'decoder_attentions',\n",
       " 'decoder_hidden_states',\n",
       " 'encoder_attentions',\n",
       " 'encoder_hidden_states',\n",
       " 'encoder_last_hidden_state',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'logits',\n",
       " 'loss',\n",
       " 'move_to_end',\n",
       " 'past_key_values',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'to_tuple',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(\n",
    "    input_ids=encoder_input_ids_,\n",
    "    attention_mask=encoder_attention_mask_,\n",
    "    decoder_input_ids=decoder_input_ids_,\n",
    "    decoder_attention_mask=decoder_attention_mask_,\n",
    "    labels=labels_,\n",
    ")\n",
    "[attr for attr in dir(outputs) if not attr.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ccdd890a07d4527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:11:46.951214Z",
     "start_time": "2024-11-09T07:11:46.947128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.9106, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c174b52a4311ef92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:13:39.596713Z",
     "start_time": "2024-11-09T07:11:47.105166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 Loss:13.6432\n",
      "Epoch: 001 Loss:14.2434\n",
      "Epoch: 002 Loss:14.2045\n",
      "Epoch: 003 Loss:14.2590\n",
      "Epoch: 004 Loss:12.7416\n",
      "Epoch: 005 Loss:13.2132\n",
      "Epoch: 006 Loss:13.6769\n",
      "Epoch: 007 Loss:14.6624\n",
      "Epoch: 008 Loss:13.9676\n",
      "Epoch: 009 Loss:11.9338\n",
      "Epoch: 010 Loss:14.3599\n",
      "Epoch: 011 Loss:14.2780\n",
      "Epoch: 012 Loss:13.6696\n",
      "Epoch: 013 Loss:15.3336\n",
      "Epoch: 014 Loss:13.8317\n",
      "Epoch: 015 Loss:12.6016\n",
      "Epoch: 016 Loss:14.3920\n",
      "Epoch: 017 Loss:15.2214\n",
      "Epoch: 018 Loss:13.3958\n",
      "Epoch: 019 Loss:13.6562\n",
      "Epoch: 020 Loss:13.5752\n",
      "Epoch: 021 Loss:15.1873\n",
      "Epoch: 022 Loss:13.4181\n",
      "Epoch: 023 Loss:14.4458\n",
      "Epoch: 024 Loss:14.1670\n",
      "Epoch: 025 Loss:14.7821\n",
      "Epoch: 026 Loss:13.8942\n",
      "Epoch: 027 Loss:13.2147\n",
      "Epoch: 028 Loss:15.1957\n",
      "Epoch: 029 Loss:14.2471\n",
      "Epoch: 030 Loss:14.4467\n",
      "Epoch: 031 Loss:15.0379\n",
      "Epoch: 032 Loss:13.5844\n",
      "Epoch: 033 Loss:13.9534\n",
      "Epoch: 034 Loss:13.4284\n",
      "Epoch: 035 Loss:13.8323\n",
      "Epoch: 036 Loss:12.6684\n",
      "Epoch: 037 Loss:12.6288\n",
      "Epoch: 038 Loss:13.6658\n",
      "Epoch: 039 Loss:15.2113\n",
      "Epoch: 040 Loss:12.8766\n",
      "Epoch: 041 Loss:13.1744\n",
      "Epoch: 042 Loss:13.7512\n",
      "Epoch: 043 Loss:14.0344\n",
      "Epoch: 044 Loss:13.5179\n",
      "Epoch: 045 Loss:14.8904\n",
      "Epoch: 046 Loss:13.5105\n",
      "Epoch: 047 Loss:13.4660\n",
      "Epoch: 048 Loss:14.0946\n",
      "Epoch: 049 Loss:12.9410\n",
      "Epoch: 050 Loss:13.2242\n",
      "Epoch: 051 Loss:12.7048\n",
      "Epoch: 052 Loss:14.7992\n",
      "Epoch: 053 Loss:14.0630\n",
      "Epoch: 054 Loss:13.6478\n",
      "Epoch: 055 Loss:13.4141\n",
      "Epoch: 056 Loss:13.0864\n",
      "Epoch: 057 Loss:14.5075\n",
      "Epoch: 058 Loss:13.3200\n",
      "Epoch: 059 Loss:13.3662\n",
      "Epoch: 060 Loss:13.3866\n",
      "Epoch: 061 Loss:13.1566\n",
      "Epoch: 062 Loss:13.7366\n",
      "Epoch: 063 Loss:13.5432\n",
      "Epoch: 064 Loss:13.2191\n",
      "Epoch: 065 Loss:13.1449\n",
      "Epoch: 066 Loss:13.8683\n",
      "Epoch: 067 Loss:12.9634\n",
      "Epoch: 068 Loss:14.1756\n",
      "Epoch: 069 Loss:13.6579\n",
      "Epoch: 070 Loss:13.0982\n",
      "Epoch: 071 Loss:13.6575\n",
      "Epoch: 072 Loss:12.5444\n",
      "Epoch: 073 Loss:12.5621\n",
      "Epoch: 074 Loss:12.7306\n",
      "Epoch: 075 Loss:12.1171\n",
      "Epoch: 076 Loss:14.2182\n",
      "Epoch: 077 Loss:13.9738\n",
      "Epoch: 078 Loss:13.5787\n",
      "Epoch: 079 Loss:13.9581\n",
      "Epoch: 080 Loss:13.6032\n",
      "Epoch: 081 Loss:14.4218\n",
      "Epoch: 082 Loss:13.1159\n",
      "Epoch: 083 Loss:12.2066\n",
      "Epoch: 084 Loss:11.8796\n",
      "Epoch: 085 Loss:12.9922\n",
      "Epoch: 086 Loss:12.9964\n",
      "Epoch: 087 Loss:14.1265\n",
      "Epoch: 088 Loss:12.4655\n",
      "Epoch: 089 Loss:13.7258\n",
      "Epoch: 090 Loss:13.1217\n",
      "Epoch: 091 Loss:13.0645\n",
      "Epoch: 092 Loss:12.7082\n",
      "Epoch: 093 Loss:13.5798\n",
      "Epoch: 094 Loss:13.6490\n",
      "Epoch: 095 Loss:12.8520\n",
      "Epoch: 096 Loss:13.4725\n",
      "Epoch: 097 Loss:13.0579\n",
      "Epoch: 098 Loss:13.9340\n",
      "Epoch: 099 Loss:13.8401\n"
     ]
    }
   ],
   "source": [
    "# let's overfit\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\").train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, weight_decay=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(\n",
    "        input_ids=encoder_input_ids_,\n",
    "        attention_mask=encoder_attention_mask_,\n",
    "        decoder_input_ids=decoder_input_ids_,\n",
    "        decoder_attention_mask=decoder_attention_mask_,\n",
    "        labels=labels_,\n",
    "    )\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {i:03d} Loss:{loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e21c29bbf9097",
   "metadata": {},
   "source": [
    "I was expecting the model loss to reduce smoothly but that didn't happen. Hmmmmm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a4768dba834c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T07:13:39.835864Z",
     "start_time": "2024-11-09T07:13:39.833651Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
