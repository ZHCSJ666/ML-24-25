{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Commit Chronicle Dataset\n",
    "\n",
    "This notebook investigates the [Commit Chronicle dataset](https://huggingface.co/datasets/JetBrains-Research/commit-chronicle) introduced in the paper [\"From Commit Message Generation to History-Aware Commit Message Completion\", ASE 2023](https://arxiv.org/abs/2308.07655) - loading, filtering, EDA and preprocessing"
   ],
   "id": "c942aa44c0386e52"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:25.620636Z",
     "start_time": "2024-11-08T16:31:24.059922Z"
    }
   },
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import rootutils\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:25.627537Z",
     "start_time": "2024-11-08T16:31:25.623637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = rootutils.find_root(\".\", \".project-root\")\n",
    "OUTPUT_DIR = ROOT / \"data/playground\""
   ],
   "id": "8947f90d5c308fd4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading and Filtering",
   "id": "929531a0d4f45abe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: Filtering logic is implemented in `CommitChroniclePreprocessor`",
   "id": "942d52de09eaa69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:25.852716Z",
     "start_time": "2024-11-08T16:31:25.812706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SPLIT = \"validation\"  # we select this split as it's small for our EDA, feel free to change to `train` split if u want\n",
    "LANGUAGES = [\"Go\"]\n",
    "\n",
    "filtered = OUTPUT_DIR / \"01-filtered\"\n",
    "\n",
    "\n",
    "# we don't directly reference `LANGUAGES` in the function because in python multiprocessing,\n",
    "# all functions passed as parameters shouldn't reference variables outside of them\n",
    "def filter_dataset(example, languages):\n",
    "    return example[\"language\"] in languages\n",
    "\n",
    "\n",
    "if not filtered.exists():\n",
    "    (\n",
    "        load_dataset(\"JetBrains-Research/commit-chronicle\", \"default\", split=SPLIT)\n",
    "        .filter(partial(filter_dataset, languages=LANGUAGES), num_proc=mp.cpu_count())\n",
    "        .save_to_disk(filtered)\n",
    "    )\n",
    "dataset = load_from_disk(filtered)"
   ],
   "id": "7bc6a878de398ee8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:25.870209Z",
     "start_time": "2024-11-08T16:31:25.862595Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.select(range(10))",
   "id": "ddc8682053d43e3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['author', 'date', 'timezone', 'hash', 'message', 'mods', 'language', 'license', 'repo', 'original_message'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "\n",
    "What kind of EDA can we possibly do?"
   ],
   "id": "f8818a3cf2413f69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:25.923208Z",
     "start_time": "2024-11-08T16:31:25.920606Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5d8476249c9784e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "\n",
    "Columns of interest in the dataset are:\n",
    "1. `mods` - Contains all file changes information - what files are changed, the type of change made (addition, modification), and the exact file changes.\n",
    "2. `message` - The (processed) git commit message\n",
    "3. `author` - (Optional) This will be used if we want to group commits by a certain author and use that as input. This is and advanced use case\n",
    "\n",
    "We are going to tokenize the `mods` and `message` using two different tokenizer, since `mods` contains code and which is quite different from `message` which is mostly natural language. So, one tokenizer for `mods`, another for `message`.\n",
    "\n",
    "We'll start with `message`. The output from the tokenization of  `message` will be called `msg_input_ids`.\n",
    "\n",
    "Note: All the preprocessing logic explored here is implemented in `CommitChroniclePreprocessor`."
   ],
   "id": "f35995929c58ee47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.102876Z",
     "start_time": "2024-11-08T16:31:25.975868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data.components.tokenization import add_special_tokens\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# This is the tokenizer used in the Commit Chronicle dataset\n",
    "# The rationale behind this choice is yet to be investigated? Someone could investigate and report :)\n",
    "# OR we may have to train our own tokenizer as suggested by our all-knowing ChatGPT (https://chatgpt.com/share/672e3b64-6b84-8009-a6c9-adac73cf647e)\n",
    "msg_tokenizer_ = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
    "\n",
    "# add `sep_token` and `pad_token`\n",
    "# `sep_token` is necessary when we are training on a history of git diffs (which is an advanced usage and not part of our initial experiments)\n",
    "# `pad_token` is necessary for correct batch construction.\n",
    "msg_tokenizer_ = add_special_tokens(msg_tokenizer_, None)"
   ],
   "id": "ab50d4730d452e17",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's try out commit message tokenization on a single example",
   "id": "dadf487d1a2e3f70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.115850Z",
     "start_time": "2024-11-08T16:31:29.109876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "msg_input_ids_ = msg_tokenizer_(\n",
    "    dataset[0][\"message\"], truncation=False, padding=False, add_special_tokens=False\n",
    ").input_ids\n",
    "\n",
    "print(dataset[0][\"message\"])\n",
    "print(msg_input_ids_)"
   ],
   "id": "326f0f8ecb12e10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add code to retrieve the correct user directory on windows and linux ... and a somewhat okayish directory on macos\"\n",
      "[986, 981, 358, 4614, 326, 3434, 729, 1867, 603, 9965, 471, 19725, 1372, 471, 279, 18016, 11304, 21194, 1468, 1867, 603, 5318, 538, 6]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we'll look at the tokenization of git commit changes, `mods`. But before we do that, let's examine the structure of the data.",
   "id": "12a06a74e9697ee6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.134481Z",
     "start_time": "2024-11-08T16:31:29.129485Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[0][\"mods\"]",
   "id": "1652316e913146be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'change_type': 'ADD',\n",
       "  'old_path': None,\n",
       "  'new_path': 'internal/config/config.go',\n",
       "  'diff': '+package config\\n+\\n+import \"strings\"\\n+\\n+var (\\n+ //AppName is the name representing the application.\\n+ AppName = \"Cordless\"\\n+ //AppNameLowercase is the representative name, but lowercase.\\n+ //It us used for filepaths and such.\\n+ AppNameLowercase = strings.ToLower(AppName)\\n+)\\n+\\n+//Config contains all possible configuration for the application.\\n+type Config struct {\\n+ Token string\\n+}\\n+\\n+var cachedConfigDir string\\n+\\n+//GetConfigDirectory is the parent directory in the os, that contains the\\n+//settings for the application.\\n+func GetConfigDirectory() (string, error) {\\n+ if cachedConfigDir != \"\" {\\n+ return cachedConfigDir, nil\\n+ }\\n+\\n+ directory, err := getConfigDirectory()\\n+ if err != nil {\\n+ return \"\", err\\n+ }\\n+\\n+ cachedConfigDir = directory\\n+ return cachedConfigDir, nil\\n+}\\n'},\n",
       " {'change_type': 'ADD',\n",
       "  'old_path': None,\n",
       "  'new_path': 'internal/config/os_darwin.go',\n",
       "  'diff': '+package config\\n+\\n+import (\\n+ \"os/user\"\\n+ \"path/filepath\"\\n+)\\n+\\n+func getConfigDirectory() (string, error) {\\n+ //TODO Gotta research this\\n+\\n+ currentUser, userError := user.Current()\\n+\\n+ if userError != nil {\\n+ return \"\", userError\\n+ }\\n+\\n+ return filepath.Join(currentUser.HomeDir, \".\"+AppNameLowercase), nil\\n+}\\n'},\n",
       " {'change_type': 'ADD',\n",
       "  'old_path': None,\n",
       "  'new_path': 'internal/config/os_linux.go',\n",
       "  'diff': '+package config\\n+\\n+import (\\n+ \"os\"\\n+ \"os/user\"\\n+ \"path/filepath\"\\n+)\\n+\\n+func getConfigDirectory() (string, error) {\\n+ configDir := os.Getenv(\"XDG_CONFIG_DIR\")\\n+\\n+ if configDir != \"\" {\\n+ return configDir, nil\\n+ }\\n+\\n+ currentUser, userError := user.Current()\\n+\\n+ if userError != nil {\\n+ return \"\", userError\\n+ }\\n+\\n+ return filepath.Join(currentUser.HomeDir, \".config\", AppNameLowercase), nil\\n+}\\n'},\n",
       " {'change_type': 'ADD',\n",
       "  'old_path': None,\n",
       "  'new_path': 'internal/config/os_windows.go',\n",
       "  'diff': '+package config\\n+\\n+import (\\n+ \"os\"\\n+ \"os/user\"\\n+ \"path/filepath\"\\n+)\\n+\\n+func getConfigDirectory() (string, error) {\\n+ configDir := os.Getenv(\"APPDATA\")\\n+\\n+ if configDir != \"\" {\\n+ return filepath.Join(configDir, AppNameLowercase), nil\\n+ }\\n+\\n+ currentUser, userError := user.Current()\\n+\\n+ if userError != nil {\\n+ return \"\", userError\\n+ }\\n+\\n+ return filepath.Join(currentUser.HomeDir, \"AppData\", \"Roaming\", AppNameLowercase), nil\\n+}\\n'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll need to somehow combine all that information into a single string before tokenization.",
   "id": "4c5e4e5b3809ba2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.180371Z",
     "start_time": "2024-11-08T16:31:29.174661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_mods(mods: list[dict[str, str]], line_sep: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms a list of all files modifications made in a commit into a single string representation.\n",
    "\n",
    "    Specifically, adds a header to each file diff (https://git-scm.com/docs/git-diff#_generating_patch_text_with_p)\n",
    "    and concatenates the results.\n",
    "\n",
    "    Args:\n",
    "        mods: A list of files modifications made in a commit.\n",
    "        line_sep: The line separator to separate each file modification.\n",
    "\n",
    "    Returns:\n",
    "        A single string representation of all files modifications made in a commit.\n",
    "    \"\"\"\n",
    "    diff = \"\"\n",
    "\n",
    "    for mod in mods:\n",
    "        if mod[\"change_type\"] == \"UNKNOWN\":\n",
    "            continue\n",
    "        elif mod[\"change_type\"] == \"ADD\":\n",
    "            file_diff = f\"new file {mod['new_path']}\"\n",
    "        elif mod[\"change_type\"] == \"DELETE\":\n",
    "            file_diff = f\"deleted file {mod['old_path']}\"\n",
    "        elif mod[\"change_type\"] == \"RENAME\":\n",
    "            file_diff = (\n",
    "                f\"rename from {mod['old_path']}{line_sep}rename to {mod['new_path']}\"\n",
    "            )\n",
    "        elif mod[\"change_type\"] == \"COPY\":\n",
    "            file_diff = (\n",
    "                f\"copy from {mod['old_path']}{line_sep}copy to {mod['new_path']}\"\n",
    "            )\n",
    "        else:\n",
    "            file_diff = f\"{mod['new_path']}\"\n",
    "        diff += file_diff + line_sep + mod[\"diff\"]\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "# Let's test it out\n",
    "print(preprocess_mods(dataset[0][\"mods\"], line_sep=\"\\n\"))"
   ],
   "id": "f55240fbafad8fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new file internal/config/config.go\n",
      "+package config\n",
      "+\n",
      "+import \"strings\"\n",
      "+\n",
      "+var (\n",
      "+ //AppName is the name representing the application.\n",
      "+ AppName = \"Cordless\"\n",
      "+ //AppNameLowercase is the representative name, but lowercase.\n",
      "+ //It us used for filepaths and such.\n",
      "+ AppNameLowercase = strings.ToLower(AppName)\n",
      "+)\n",
      "+\n",
      "+//Config contains all possible configuration for the application.\n",
      "+type Config struct {\n",
      "+ Token string\n",
      "+}\n",
      "+\n",
      "+var cachedConfigDir string\n",
      "+\n",
      "+//GetConfigDirectory is the parent directory in the os, that contains the\n",
      "+//settings for the application.\n",
      "+func GetConfigDirectory() (string, error) {\n",
      "+ if cachedConfigDir != \"\" {\n",
      "+ return cachedConfigDir, nil\n",
      "+ }\n",
      "+\n",
      "+ directory, err := getConfigDirectory()\n",
      "+ if err != nil {\n",
      "+ return \"\", err\n",
      "+ }\n",
      "+\n",
      "+ cachedConfigDir = directory\n",
      "+ return cachedConfigDir, nil\n",
      "+}\n",
      "new file internal/config/os_darwin.go\n",
      "+package config\n",
      "+\n",
      "+import (\n",
      "+ \"os/user\"\n",
      "+ \"path/filepath\"\n",
      "+)\n",
      "+\n",
      "+func getConfigDirectory() (string, error) {\n",
      "+ //TODO Gotta research this\n",
      "+\n",
      "+ currentUser, userError := user.Current()\n",
      "+\n",
      "+ if userError != nil {\n",
      "+ return \"\", userError\n",
      "+ }\n",
      "+\n",
      "+ return filepath.Join(currentUser.HomeDir, \".\"+AppNameLowercase), nil\n",
      "+}\n",
      "new file internal/config/os_linux.go\n",
      "+package config\n",
      "+\n",
      "+import (\n",
      "+ \"os\"\n",
      "+ \"os/user\"\n",
      "+ \"path/filepath\"\n",
      "+)\n",
      "+\n",
      "+func getConfigDirectory() (string, error) {\n",
      "+ configDir := os.Getenv(\"XDG_CONFIG_DIR\")\n",
      "+\n",
      "+ if configDir != \"\" {\n",
      "+ return configDir, nil\n",
      "+ }\n",
      "+\n",
      "+ currentUser, userError := user.Current()\n",
      "+\n",
      "+ if userError != nil {\n",
      "+ return \"\", userError\n",
      "+ }\n",
      "+\n",
      "+ return filepath.Join(currentUser.HomeDir, \".config\", AppNameLowercase), nil\n",
      "+}\n",
      "new file internal/config/os_windows.go\n",
      "+package config\n",
      "+\n",
      "+import (\n",
      "+ \"os\"\n",
      "+ \"os/user\"\n",
      "+ \"path/filepath\"\n",
      "+)\n",
      "+\n",
      "+func getConfigDirectory() (string, error) {\n",
      "+ configDir := os.Getenv(\"APPDATA\")\n",
      "+\n",
      "+ if configDir != \"\" {\n",
      "+ return filepath.Join(configDir, AppNameLowercase), nil\n",
      "+ }\n",
      "+\n",
      "+ currentUser, userError := user.Current()\n",
      "+\n",
      "+ if userError != nil {\n",
      "+ return \"\", userError\n",
      "+ }\n",
      "+\n",
      "+ return filepath.Join(currentUser.HomeDir, \"AppData\", \"Roaming\", AppNameLowercase), nil\n",
      "+}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now onto tokenization of the concatenated git diff or `mods`",
   "id": "7ed10213cf9ba57b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.300053Z",
     "start_time": "2024-11-08T16:31:29.223386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Here, we just duplicate the message tokenizer, but it could be completely different, or maybe I lied :)\n",
    "diff_tokenizer_ = deepcopy(msg_tokenizer_)\n",
    "# diff can be very long, we need to set a limit that our model (and computer resources) can handle\n",
    "DIFF_MAX_LEN = 512\n",
    "\n",
    "# again, let's test it\n",
    "git_diff_ = preprocess_mods(dataset[0][\"mods\"], line_sep=\"\\n\")\n",
    "diff_input_ids_ = diff_tokenizer_(\n",
    "    git_diff_,\n",
    "    truncation=True,\n",
    "    max_length=DIFF_MAX_LEN\n",
    "    - 2,  # -2 to account for special tokens (BOS and EOS) to be added later, during batch data construction.\n",
    "    padding=False,\n",
    "    add_special_tokens=False,\n",
    ").input_ids\n",
    "print(diff_input_ids_[:100], len(diff_input_ids_))"
   ],
   "id": "ce7d1f7e44faf6e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2704, 585, 2713, 19, 1425, 19, 1425, 18, 3240, 203, 15, 5610, 642, 203, 15, 203, 15, 5666, 315, 10219, 6, 203, 15, 203, 15, 1401, 261, 203, 15, 368, 3371, 461, 353, 326, 508, 5123, 326, 2521, 18, 203, 15, 4677, 461, 273, 315, 39, 517, 2656, 6, 203, 15, 368, 3371, 461, 4070, 3593, 353, 326, 23174, 508, 16, 1496, 12400, 18, 203, 15, 368, 7193, 584, 1399, 364, 3608, 87, 471, 4123, 18, 203, 15, 4677, 461, 4070, 3593, 273, 2064, 18, 774, 4070, 12, 3371, 461, 13, 203, 6975, 203, 15, 203, 15, 759, 809, 1914] 510\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's put everything together to process `mods` and `message` columns for all rows in the dataset.",
   "id": "88139463173dfc1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.363937Z",
     "start_time": "2024-11-08T16:31:29.312939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_example(\n",
    "    example,\n",
    "    msg_tokenizer,\n",
    "    diff_tokenizer,\n",
    "    diff_max_len,\n",
    "    diff_line_sep,\n",
    "    preprocess_mods_func,\n",
    "):\n",
    "    msg_input_ids = msg_tokenizer(\n",
    "        example[\"message\"], truncation=False, padding=False, add_special_tokens=False\n",
    "    ).input_ids\n",
    "\n",
    "    git_diff = preprocess_mods_func(example[\"mods\"], line_sep=diff_line_sep)\n",
    "    diff_input_ids = diff_tokenizer(\n",
    "        git_diff,\n",
    "        truncation=True,  # we unfortunately have to truncate the git changes\n",
    "        max_length=diff_max_len\n",
    "        - 2,  # -2 to account for special tokens (BOS and EOS) to be added later, during batch data construction.\n",
    "        padding=False,\n",
    "        add_special_tokens=False,\n",
    "    ).input_ids\n",
    "\n",
    "    return {\n",
    "        \"author\": example[\"author\"],\n",
    "        \"message\": example[\"message\"],\n",
    "        \"msg_input_ids\": msg_input_ids,\n",
    "        \"diff_input_ids\": diff_input_ids,\n",
    "        \"repo\": example[\"repo\"],\n",
    "        \"language\": example[\"language\"],\n",
    "    }\n",
    "\n",
    "\n",
    "processed = OUTPUT_DIR / \"02-processed\"\n",
    "if not processed.exists():\n",
    "    (\n",
    "        dataset.map(\n",
    "            partial(\n",
    "                process_example,\n",
    "                msg_tokenizer=msg_tokenizer_,\n",
    "                diff_tokenizer=diff_tokenizer_,\n",
    "                diff_max_len=DIFF_MAX_LEN,\n",
    "                diff_line_sep=\"\\n\",\n",
    "                preprocess_mods_func=preprocess_mods,\n",
    "            ),\n",
    "            num_proc=mp.cpu_count(),\n",
    "        )\n",
    "        .select_columns(\n",
    "            [\"author\", \"msg_input_ids\", \"diff_input_ids\", \"language\", \"repo\"]\n",
    "        )\n",
    "        .save_to_disk(processed)\n",
    "    )\n",
    "dataset = load_from_disk(processed)"
   ],
   "id": "29d987b1978ede38",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.382428Z",
     "start_time": "2024-11-08T16:31:29.376823Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.select(range(10))",
   "id": "20298f8df7a86574",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['author', 'msg_input_ids', 'diff_input_ids', 'language', 'repo'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:29.435467Z",
     "start_time": "2024-11-08T16:31:29.433330Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "215d62de898d39a6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
