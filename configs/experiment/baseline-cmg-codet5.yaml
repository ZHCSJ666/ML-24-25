# @package _global_

defaults:
  - override /data: commit-chronicle
  - override /callbacks: default
  - override /trainer: gpu
  - override /logger: tensorboard

tags: ["commit-chronicle", "codet5", "t5", "baseline"]

seed: 12345

trainer:
  min_epochs: 10
  max_epochs: 20
#  gradient_clip_val: 1

model:
  _target_: src.models.CommitMessageGenerationModule
  net:
    _target_: models.components.seq2seq_wrapper.Seq2SeqWrapper
    encoder_vocab_size:
      _target_: builtins.len
      _args_:
        - ${data.diff_tokenizer}
    decoder_vocab_size:
      _target_: builtins.len
      _args_:
        - ${data.msg_tokenizer}
    model:
      _target_: transformers.AutoModelForSeq2SeqLM
      pretrained_model_name_or_path: JetBrains-Research/cmg-codet5-without-history

data:
  batch_size: 16
  diff_max_len: 512
  msg_max_len: 512
  diff_tokenizer:
    name_or_path: JetBrains-Research/cmg-codet5-without-history
  msg_tokenizer:
    name_or_path: JetBrains-Research/cmg-codet5-without-history


# not interested in training baseline models
train: False