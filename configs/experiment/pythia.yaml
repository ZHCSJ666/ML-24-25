# @package _global_

defaults:
  - override /data: commit-chronicle-clm
  - override /model: pythia
  - override /callbacks: default
  - override /trainer: gpu
  - override /logger: tensorboard

tags: ["commit-chronicle", "clm", "pythia"]

seed: 12345

trainer:
  min_epochs: 10
  max_epochs: 20
#  gradient_clip_val: 1

model:
  net:
    tokenizer: ${data.tokenizer}
    config:
      num_hidden_layers: 1
      max_position_embeddings: 1024
      intermediate_size: 256
  generation_kwargs:
    max_new_tokens: 64


data:
  change_types:
  batch_size: 16
  tokenizer:
    name_or_path: EleutherAI/pythia-14m # Salesforce/codet5-small
    padding_side: left # https://huggingface.co/docs/transformers/en/llm_tutorial#wrong-padding-side
